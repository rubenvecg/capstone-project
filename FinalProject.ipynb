{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: The Battle of the Neighborhoods (Week 2)\n",
    "### Applied Data Science Captstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#intro)\n",
    "* [Data](#data)\n",
    "* [Setting up](#setup)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Business Problem <a name='introduction'></a>\n",
    "\n",
    "It is well known that **pizza** is quite popular in **New York City**. With lots of pizzerias available throughout the city, stakeholders interested in opening a new parlor may encounter heavy competition. I will aim to use **data science** techniques to determine areas within the city with not too many options for pizza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name='data'></a>\n",
    "\n",
    "The main data used will come from the **Foursquare Places API**. It allows developers to search explore venues based on a cetnered location. We can search for venues available within a radius for each neighborhood in NYC.\n",
    "\n",
    "Additionally, I will use a **GeoJSON file** containing information about the neighborhoods in NYC to extract the borough, name, latitude and longitude values for each neighborhood. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up <a name='setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas and numpy will be sued to read our .csv, json, and geojson files\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "#requests will be used to do our API reuests for the Foursquare API\n",
    "import requests\n",
    "\n",
    "#KMeans for neighborhood clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Mapping tool\n",
    "import folium\n",
    "\n",
    "#Set up pandas options to diaply the whole dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting neighborhood Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our libraries imported, we can collect our data. Let's load the data from **newyork_data.json** on a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>40.894705</td>\n",
       "      <td>-73.847201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Co-op City</td>\n",
       "      <td>40.874294</td>\n",
       "      <td>-73.829939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Eastchester</td>\n",
       "      <td>40.887556</td>\n",
       "      <td>-73.827806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Fieldston</td>\n",
       "      <td>40.895437</td>\n",
       "      <td>-73.905643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Riverdale</td>\n",
       "      <td>40.890834</td>\n",
       "      <td>-73.912585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Borough         Name   Latitude  Longitude\n",
       "0   Bronx    Wakefield  40.894705 -73.847201\n",
       "1   Bronx   Co-op City  40.874294 -73.829939\n",
       "2   Bronx  Eastchester  40.887556 -73.827806\n",
       "3   Bronx    Fieldston  40.895437 -73.905643\n",
       "4   Bronx    Riverdale  40.890834 -73.912585"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load json\n",
    "nyc_data = json.load(open('newyork_data.json'))\n",
    "\n",
    "#Initialize dataframe with custom named columns\n",
    "column_names = ['Borough','Name', 'Latitude', 'Longitude']\n",
    "df_neighborhoods = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#Iterate through json features and append each neighborhood to the dataframe\n",
    "for i, row in enumerate(nyc_data['features']):\n",
    "    df_neighborhoods.loc[i,:] = ([row['properties']['borough'],\n",
    "                                 row['properties']['name'],\n",
    "                                 row['geometry']['coordinates'][1],\n",
    "                                 row['geometry']['coordinates'][0]])\n",
    "    \n",
    "#Verify that we have 306 neighborhoods saved on the dataframe\n",
    "print(df_neighborhoods.shape)\n",
    "\n",
    "df_neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API setup\n",
    "We have our neighborhoods, now let's set up our API url. In order to use the Foursquare API, you need a **client ID, client secret and access_token** provided by <a href='https://foursquare.com/'>Foursquare</a> once you create a developer account. All my keys are saved on an external file called **keys.py** for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.foursquare.com/v2/venues/explore?client_id=JHTTDJBJUFNGC3N1HBTYRWA5PBBIPAG04DOWOCMZACIGD2VS&client_secret=RRJE5IIXHSWYNP5ZFA2MXM40N4BNFU5AQQQQYAEZMGKEE1NM&oauth_token=31MZ5WDVPNAUOBFVXDBQPVARI2V31JM1VETVND4GAZOYILXX&v=20180604&limit=500\n"
     ]
    }
   ],
   "source": [
    "import keys\n",
    "\n",
    "# Replace the values here for your own keys in order to call the API\n",
    "CLIENT_ID = keys.CLIENT_ID\n",
    "CLIENT_SECRET = keys.CLIENT_SECRET\n",
    "ACCESS_TOKEN = keys.ACCESS_TOKEN\n",
    "VERSION = '20180604'\n",
    "LIMIT = 500\n",
    "credentials = \"client_id={}&client_secret={}&oauth_token={}\".format(CLIENT_ID, CLIENT_SECRET, ACCESS_TOKEN)\n",
    "parameters = \"v={}&limit={}\".format(VERSION, LIMIT)\n",
    "\n",
    "search_url = \"https://api.foursquare.com/v2/venues/explore?{}&{}\".format(credentials, parameters)\n",
    "print(search_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing needed to get venue information is to add our query parameters. Let's create a method that, given a pandas dataframe with neighborhood data, makess an API call for each row's latitude and longitude values to get the venues within 500 meters within the center of those coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The categories field is composed of other children fields. We are only interested in the name\n",
    "def get_cat_name(row):\n",
    "    try:\n",
    "        #Extract name of venue category\n",
    "        return row['Category'][0]['name']\n",
    "    except:\n",
    "        #If there is no category available, return None\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "def get_nearby_venues(neighborhoods, url, radius): \n",
    "    \n",
    "    #Initialize dataframe    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for b, n, lat, lon in zip(neighborhoods['Borough'],neighborhoods['Name'], neighborhoods['Latitude'], \n",
    "                              neighborhoods['Longitude']):\n",
    "\n",
    "        search_query = url + \"&ll={},{}&radius={}\".format(lat, lon, radius)\n",
    "\n",
    "        response = requests.get(search_query).json()[\"response\"]['groups'][0]['items']  \n",
    "        \n",
    "        #Print neighborhood name and number of found venues\n",
    "        print(n, len(response), 'venues')\n",
    "\n",
    "        df = df.append([(b, n, v['venue']['name'],\n",
    "                               v['venue']['categories'],\n",
    "                               v['venue']['location']['lat'],\n",
    "                               v['venue']['location']['lng']) for v in response])\n",
    "\n",
    "    \n",
    "    #Assign columns\n",
    "    columns = ['Borough', 'Neighborhood', 'Name', 'Category', 'Latitude', 'Longitude']\n",
    "    df.columns = columns\n",
    "    \n",
    "    #Extract category name from categories\n",
    "    df['Category'] = df.apply(get_cat_name, axis=1)\n",
    "    \n",
    "    #Remove misleading venue categories\n",
    "    df = df[~df['Category'].isin(['Food','Neighborhood'])]\n",
    "    \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function it's ready. Let's make our call. It will take a couple of minutes to build the whole dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venues = get_nearby_venues(df_neighborhoods, search_url, 750)\n",
    "df_venues.to_csv('venues.csv',index=False)\n",
    "\n",
    "print(df_venues.shape)\n",
    "df_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology <a name='methodology'></a>\n",
    "\n",
    "We now have a dataframe with venue information in New York City. To find the best neighborhoods to open a pizza parlor, we will utilize the k-means algorith to group the neighborhoods in 5 clusters based on the list of most frequent venues by neighborhood.\n",
    "\n",
    "In order to do so, we need to convert the neighborhood category data that is currently categorical to numerical values. For that we will apply **one-hot encoding** to our **Category** row. This will basically create a new column named after each different value for Category and the values will be 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the one-hot encodign dataframe\n",
    "df_onehot = pd.get_dummies(df_venues['Category'], prefix='', prefix_sep='')\n",
    "\n",
    "# Add Borough and Neighborhood to the dataframe. Since some neighborhoods in different boroughs are named the same. The borough will belp\n",
    "# make that distinction\n",
    "df_onehot['Borough'] = df_venues['Borough']\n",
    "df_onehot['Neighborhood'] = df_venues['Neighborhood']\n",
    "\n",
    "# Rearrange columns moving Borough and Neighborhood to the left\n",
    "columns = list(df_onehot.columns[-2:]) + list(df_onehot.columns[:-2])\n",
    "df_onehot = df_onehot[columns]\n",
    "\n",
    "# Group by neighborhood\n",
    "df_onehot = df_onehot.groupby(by=['Borough','Neighborhood']).mean()\n",
    "\n",
    "df_onehot.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "print(df_onehot.shape)\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a dataframe with the top 10 most frequent venues by neighborhood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our columns\n",
    "indicators = ['st','nd','rd','th']\n",
    "columns = ['Borough', 'Neighborhood'] + [str(i+1) + (indicators[i] if i < len(indicators)-1 else indicators[-1]) + ' Most Frequent Venue' for i in range(0,10)]\n",
    "\n",
    "df_top10 = pd.DataFrame(columns=columns)\n",
    "\n",
    "for b,n in zip(df_onehot['Borough'], df_onehot['Neighborhood']):\n",
    "    \n",
    "    # Get dataframe for specific neighborhood and transpose it\n",
    "    df_n = df_onehot[(df_onehot['Neighborhood'] == n) & (df_onehot['Borough'] == b)]\n",
    "    \n",
    "    # Remove Neighborhood & Borough columns\n",
    "    df_n = df_n.drop(['Borough','Neighborhood'], axis=1)\n",
    "    \n",
    "    # Transpose dataframe\n",
    "    df_n = df_n.transpose().reset_index()\n",
    "        \n",
    "    # Rename columns\n",
    "    df_n.columns = ['Venue', 'Frequency']\n",
    "        \n",
    "    # Get 10 most requent locations and keep only Venue\n",
    "    df_n = df_n.sort_values(by='Frequency', ascending=False)[['Venue']].head(10) \n",
    "    \n",
    "    # Transpose again, add neighborhood and rename columns\n",
    "    df_n = df_n.transpose().reset_index(drop=True)\n",
    "    \n",
    "    # Add borough and neighborhood and move to the left\n",
    "    df_n['Borough'] = b \n",
    "    df_n['Neighborhood'] = n    \n",
    "    df_n = df_n[list(df_n.columns[-2:]) + list(df_n.columns[:-2])]\n",
    "    \n",
    "    df_n.columns = columns\n",
    "    \n",
    "    #Append to DataFrame\n",
    "    df_top10 = df_top10.append(df_n)\n",
    "    \n",
    "    del(df_n)\n",
    "\n",
    "print(df_top10.shape)\n",
    "df_top10.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge df_top10 and df_neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our original nieghborhoods dataframe had Name instead of Neighborhood. Let's rename our columns to merge our datasets\n",
    "df_neighborhoods.columns = ['Borough', 'Neighborhood', 'Latitude', 'Longitude']\n",
    "df_cluster = pd.merge(df_neighborhoods, df_top10, on=['Borough','Neighborhood'])\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run kmeans clustering on our dataframe. For that, we will utilize the KMeans package from **sci-kit learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(df_onehot.drop(['Borough','Neighborhood'], 1))\n",
    "\n",
    "# Add cluster values to dataframe\n",
    "df_cluster['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis <a name='analysis'></a>\n",
    "\n",
    "Our neighborhoods are now clustered. However, we haven't found our neighborhoods yet. Let's visualize our clusters on the map. For that we will create function that will create a Folium map object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC Coordinates\n",
    "latitude = 40.712\n",
    "longitude = -74.005\n",
    "\n",
    "import folium\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as colors\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def map_clusters(df):\n",
    "\n",
    "    cmap = list(cm.rainbow(np.linspace(0, 1, len(set(kmeans.labels_)))))\n",
    "    cmap = [colors.rgb2hex(i) for i in cmap]\n",
    "    map_nyc_clustered = folium.Map(location=[latitude, longitude], zoom_start=11.2, tiles='cartodbpositron')\n",
    "\n",
    "    for neighborhood, cluster, lat, lon, in zip(df['Neighborhood'],\n",
    "                                                df['Cluster'],\n",
    "                                                df['Latitude'],\n",
    "                                                df['Longitude']):\n",
    "\n",
    "        label = folium.Popup('{}, {}'.format(neighborhood, cluster), parse_html = False)\n",
    "\n",
    "        folium.CircleMarker(\n",
    "                [lat, lon],\n",
    "                radius=5,\n",
    "                popup=label,\n",
    "                color=None,\n",
    "               fill=True,\n",
    "                fill_color=cmap[cluster],\n",
    "                fill_opacity=0.7,\n",
    "                parse_html=False).add_to(map_nyc_clustered)\n",
    "        \n",
    "    return map_nyc_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_clusters(df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand a little better our clusters. We can group our dataframe by cluster count the appearances of Pizza Place as nth most frequent venue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_columns = ['Pizza Place as ' + c for c in columns[2:]]\n",
    "df_count = pd.DataFrame(columns=new_columns)\n",
    "\n",
    "for c, nc in zip(columns[2:], new_columns):     \n",
    "    values = df_cluster.groupby('Cluster')[c].value_counts().values.tolist()\n",
    "    indices = [[c[0], values[i]] for i,c in enumerate(df_cluster.groupby('Cluster')[c].value_counts().index.tolist()) if 'Pizza Place' in c[1]]\n",
    "    for i in indices:\n",
    "        df_count.loc[i[0],nc] = i[1]\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df_count = df_count.fillna(0)\n",
    "\n",
    "# Sum all values into total\n",
    "df_count['Total'] = df_count['Total'] = df_count[new_columns].sum(axis=1)\n",
    "\n",
    "df_count.sort_values(by='Total', ascending=True, inplace=True)\n",
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results <a name='results'></a>\n",
    "As we can see, the top clusters hae the least amount of pizzerias. The more rows we choose we can expand our options of neighborhoods. Let's stick with the top 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters(df_cluster[df_cluster['Cluster'].isin(df_count.head(3).index.values.tolist())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name='conclusion'></a>\n",
    "KMeans clustering is a powerful algorithm that can provide us with good insights of how data is distributed. Of course, there are other factors that can improve our decision making such as demographics and psycographic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
